{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed041734",
   "metadata": {},
   "source": [
    "# PlantCLEF 2025 Inference API\n",
    "\n",
    "**Purpose:** Provide REST API endpoint for plant identification using PlantCLEF 2025 dataset\n",
    "\n",
    "**Dataset:** PlantCLEF 2025 (1TB+, 10,000+ species)\n",
    "\n",
    "**Usage:**\n",
    "1. Upload this notebook to Kaggle\n",
    "2. Add PlantCLEF 2025 dataset\n",
    "3. Enable internet access\n",
    "4. Run all cells\n",
    "5. Use ngrok URL as API endpoint\n",
    "\n",
    "**API Endpoint:**\n",
    "```\n",
    "POST /predict\n",
    "Content-Type: multipart/form-data\n",
    "Body: image file\n",
    "\n",
    "Response:\n",
    "{\n",
    "  \"predictions\": [\n",
    "    {\"species\": \"Rosa damascena\", \"confidence\": 0.95, \"common_name\": \"Damascus Rose\"},\n",
    "    ...\n",
    "  ],\n",
    "  \"inference_time\": 2.3,\n",
    "  \"model\": \"PlantCLEF-2025-ResNet50\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10022fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install flask flask-cors pyngrok pillow torch torchvision timm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87227781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "import timm\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc973a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path (Kaggle Input)\n",
    "DATASET_PATH = '/kaggle/input/plantclef2025'\n",
    "\n",
    "# Check if dataset exists\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(f\"‚úÖ PlantCLEF 2025 dataset found at {DATASET_PATH}\")\n",
    "    # List first few directories\n",
    "    subdirs = os.listdir(DATASET_PATH)[:10]\n",
    "    print(f\"üìÅ First 10 directories: {subdirs}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found! Please add PlantCLEF 2025 dataset to this notebook.\")\n",
    "    print(\"   Go to: Add Data > Search 'PlantCLEF 2025'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load species mapping\n",
    "# PlantCLEF 2025 typically has a species_map.json or similar\n",
    "species_map = {}\n",
    "species_map_path = os.path.join(DATASET_PATH, 'species_map.json')\n",
    "\n",
    "if os.path.exists(species_map_path):\n",
    "    with open(species_map_path, 'r') as f:\n",
    "        species_map = json.load(f)\n",
    "    print(f\"‚úÖ Loaded {len(species_map)} species mappings\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Species map not found, using directory names as species IDs\")\n",
    "    # Create mapping from directory names\n",
    "    if os.path.exists(DATASET_PATH):\n",
    "        species_dirs = [d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))]\n",
    "        species_map = {str(i): name for i, name in enumerate(species_dirs)}\n",
    "        print(f\"‚úÖ Created mapping for {len(species_map)} species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "# Option 1: Load from Kaggle models (if available)\n",
    "# Option 2: Load pretrained ResNet/EfficientNet and fine-tune\n",
    "# Option 3: Use timm library for plant classification models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üéÆ Using device: {device}\")\n",
    "\n",
    "# Load model (example: ResNet50 pretrained on ImageNet, can be fine-tuned)\n",
    "model_name = 'resnet50'\n",
    "num_classes = len(species_map) if species_map else 10000  # PlantCLEF has ~10k species\n",
    "\n",
    "print(f\"üì¶ Loading model: {model_name}\")\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_image(image_bytes, top_k=5):\n",
    "    \"\"\"\n",
    "    Predict plant species from image bytes\n",
    "    \n",
    "    Args:\n",
    "        image_bytes: Image file bytes\n",
    "        top_k: Number of top predictions to return\n",
    "    \n",
    "    Returns:\n",
    "        List of predictions with species, confidence, and common name\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load image\n",
    "    image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "    \n",
    "    # Preprocess\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        top_probs, top_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    # Format results\n",
    "    predictions = []\n",
    "    for prob, idx in zip(top_probs[0].cpu().numpy(), top_indices[0].cpu().numpy()):\n",
    "        species_id = str(idx)\n",
    "        species_name = species_map.get(species_id, f\"Unknown_Species_{idx}\")\n",
    "        \n",
    "        predictions.append({\n",
    "            \"species\": species_name,\n",
    "            \"confidence\": float(prob),\n",
    "            \"common_name\": species_name.replace('_', ' ').title(),\n",
    "            \"species_id\": species_id\n",
    "        })\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": predictions,\n",
    "        \"inference_time\": round(inference_time, 3),\n",
    "        \"model\": model_name,\n",
    "        \"device\": str(device)\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Prediction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb24114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Flask API\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for external access\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return jsonify({\n",
    "        \"service\": \"PlantCLEF 2025 Inference API\",\n",
    "        \"status\": \"running\",\n",
    "        \"model\": model_name,\n",
    "        \"num_species\": len(species_map),\n",
    "        \"endpoints\": {\n",
    "            \"/\": \"GET - Service info\",\n",
    "            \"/predict\": \"POST - Plant identification (multipart/form-data)\",\n",
    "            \"/health\": \"GET - Health check\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\n",
    "        \"status\": \"healthy\",\n",
    "        \"model_loaded\": True,\n",
    "        \"device\": str(device),\n",
    "        \"cuda_available\": torch.cuda.is_available()\n",
    "    })\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Check if image file is present\n",
    "        if 'image' not in request.files:\n",
    "            return jsonify({\"error\": \"No image file provided\"}), 400\n",
    "        \n",
    "        file = request.files['image']\n",
    "        if file.filename == '':\n",
    "            return jsonify({\"error\": \"Empty filename\"}), 400\n",
    "        \n",
    "        # Read image bytes\n",
    "        image_bytes = file.read()\n",
    "        \n",
    "        # Get top_k parameter (default 5)\n",
    "        top_k = int(request.form.get('top_k', 5))\n",
    "        \n",
    "        # Predict\n",
    "        result = predict_image(image_bytes, top_k=top_k)\n",
    "        \n",
    "        return jsonify(result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            \"error\": str(e),\n",
    "            \"type\": type(e).__name__\n",
    "        }), 500\n",
    "\n",
    "print(\"‚úÖ Flask API created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ngrok tunnel (for external access)\n",
    "# You'll need an ngrok auth token\n",
    "# Get free token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"  # Replace with your token\n",
    "\n",
    "if NGROK_AUTH_TOKEN != \"YOUR_NGROK_TOKEN_HERE\":\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    print(\"‚úÖ Ngrok auth token set\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please set your ngrok auth token above\")\n",
    "    print(\"   Get one free at: https://dashboard.ngrok.com/get-started/your-authtoken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9502101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Flask server with ngrok tunnel\n",
    "from threading import Thread\n",
    "\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "\n",
    "# Start Flask in background thread\n",
    "thread = Thread(target=run_flask)\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "# Wait for Flask to start\n",
    "time.sleep(2)\n",
    "\n",
    "# Create ngrok tunnel\n",
    "if NGROK_AUTH_TOKEN != \"YOUR_NGROK_TOKEN_HERE\":\n",
    "    public_url = ngrok.connect(5000)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üåê PUBLIC API URL:\")\n",
    "    print(f\"   {public_url}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüìù Usage:\")\n",
    "    print(f\"   curl -X POST {public_url}/predict -F 'image=@plant.jpg'\")\n",
    "    print(\"\\n‚ö†Ô∏è Copy this URL to your backend .env file as KAGGLE_NOTEBOOK_URL\")\n",
    "    print(\"\\nüîÑ Keep this notebook running to maintain the API endpoint\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Ngrok token not set, API only available locally on port 5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3710102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep notebook alive\n",
    "print(\"‚úÖ API Server is running!\")\n",
    "print(\"   Press Ctrl+C to stop (but this will stop the API)\")\n",
    "print(\"   Keep this cell running to maintain the API endpoint\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(60)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüõë Server stopped\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
