"""
LLM Service - Simple template-based response generator
Uses plant data from recognition APIs without external LLM
"""

import logging
from typing import Optional, List, Dict

logger = logging.getLogger(__name__)


class LLMService:
    """Template-based plant response generator"""

    def __init__(self):
        logger.info("âœ… Template-based response generator initialized")

    async def generate_response(
        self, prompt: str, context: Optional[str] = None
    ) -> str:
        """Generate response using templates and context"""
        return self._generate_plant_response(prompt, context)

    def _generate_plant_response(
        self, prompt: str, context: Optional[str] = None
    ) -> str:
        """Generate formatted plant response from context"""
        if not context:
            return "Bitki analizi yapÄ±ldÄ± ancak eÅŸleÅŸen sonuÃ§ bulunamadÄ±. LÃ¼tfen daha net bir gÃ¶rsel ile tekrar deneyin."

        # Parse context to extract plant info
        response_parts = ["ðŸŒ¿ **GÃ¶rsel Analizi TamamlandÄ±!**\n"]

        # Add context directly - it's already formatted
        response_parts.append("**Bulunan Bitkiler:**")
        response_parts.append(context)
        response_parts.append("")

        # Add helpful info based on query type
        query_lower = prompt.lower()

        if any(word in query_lower for word in ["bakÄ±m", "sulama", "yetiÅŸtir", "care"]):
            response_parts.append("**ðŸ’¡ BakÄ±m Ã–nerileri:**")
            response_parts.append("- Bitkinin tÃ¼rÃ¼ne gÃ¶re sulama ihtiyacÄ± deÄŸiÅŸir")
            response_parts.append("- DolaylÄ± gÃ¼neÅŸ Ä±ÅŸÄ±ÄŸÄ± Ã§oÄŸu bitki iÃ§in idealdir")
            response_parts.append("- TopraÄŸÄ±n Ã¼st kÄ±smÄ± kuruduÄŸunda sulayÄ±n")

        elif any(
            word in query_lower for word in ["zehir", "tehlike", "toxic", "poison"]
        ):
            response_parts.append("**âš ï¸ UyarÄ±:**")
            response_parts.append(
                "- BazÄ± bitkiler evcil hayvanlar iÃ§in zararlÄ± olabilir"
            )
            response_parts.append("- DetaylÄ± bilgi iÃ§in uzman gÃ¶rÃ¼ÅŸÃ¼ alÄ±n")

        else:
            response_parts.append("**ðŸ“ Not:**")
            response_parts.append(
                "- YukarÄ±daki bilgiler Kaggle PlantCLEF, PlantNet ve USDA veritabanlarÄ±ndan alÄ±nmÄ±ÅŸtÄ±r"
            )
            response_parts.append("- Kesin tanÄ±mlama iÃ§in uzman gÃ¶rÃ¼ÅŸÃ¼ Ã¶nerilir")

        return "\n".join(response_parts)

    async def generate_rag_response(
        self, query: str, context: str, plants: list = None
    ) -> str:
        """RAG response with plant context"""
        return await self.generate_response(query, context)


# Global instance
grok_service = LLMService()
